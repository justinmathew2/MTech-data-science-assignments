{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbWkic2k-n2"
      },
      "source": [
        "# <center>        **Natural Language Processing - ASSIGNMENT 2**</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2gFFo0klJ0j"
      },
      "source": [
        "# **Problem Statement:**\n",
        "\n",
        "**Sentence: \"Generative AI has brought unprecedented disruption\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ35yfQjRtHm"
      },
      "source": [
        "**1) Print the pos tag of the sentence and explain the output (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhzRb8xnkgiL",
        "outputId": "a16c255f-b2c7-4473-bc9a-1cf684261988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "#Importing necessary Libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import CFG, ChartParser, ViterbiParser, PCFG\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2GSv8Uek9eu",
        "outputId": "8f363d4e-92a3-4228-f346-46934c42288c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Generative', 'NNP'), ('AI', 'NNP'), ('has', 'VBZ'), ('brought', 'VBN'), ('unprecedented', 'JJ'), ('disruption', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Generative AI has brought unprecedented disruption\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAwBwM06nfKY"
      },
      "source": [
        "# **Observation:**\n",
        "\n",
        "\n",
        "*   This Code involves assigning specific grammatical categories or labels (such as nouns, verbs, adjectives, adverbs, pronouns, etc.) to individual words within a sentence.\n",
        "*   The output provides pairs of words from the sentence along with their corresponding part-of-speech tags.\n",
        "\n",
        "# **Inferences:**\n",
        "\n",
        "\n",
        "*   This classification helps identify the sentence's structure and the roles of different words within it.\n",
        "*   This allows us to identify the grammatical roles of each word in the sentence, which helps in further syntactic analysis and understanding of the sentence structure.\n",
        "\n",
        "# **Explanation:**\n",
        "\n",
        "The output shows each word in the input sentence along with its corresponding part-of-speech (POS) tag. The POS tag indicates the grammatical category of the word, such as whether it is a noun, verb, adjective, etc. In this case:\n",
        "\n",
        "'Generative' and 'AI' are identified as proper nouns (NNP).\n",
        "'has' is identified as a verb in the present tense, third person singular (VBZ).\n",
        "'brought' is identified as a verb in the past participle form (VBN).\n",
        "'unprecedented' is identified as an adjective (JJ).\n",
        "'disruption' is identified as a noun (NN).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TlVJ8z1wVHj"
      },
      "source": [
        "**2) Print the top down parser and explain the output (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDbd1SBgS8iK",
        "outputId": "277919f4-13c4-4baa-a340-a823bddaa6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S --->\n",
            "    | NP --->\n",
            "    |     | NNP --->\n",
            "    |     |     | Generative\n",
            "    |     | NNP --->\n",
            "    |     |     | AI\n",
            "    | VP --->\n",
            "    |     | VBZ --->\n",
            "    |     |     | has\n",
            "    |     | VP --->\n",
            "    |     |     | VBN --->\n",
            "    |     |     |     | brought\n",
            "    |     |     | NP --->\n",
            "    |     |     |     | JJ --->\n",
            "    |     |     |     |     | unprecedented\n",
            "    |     |     |     | NN --->\n",
            "    |     |     |     |     | disruption\n"
          ]
        }
      ],
      "source": [
        "# Define a custom context-free grammar\n",
        "custom_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> JJ NN | NNP NNP\n",
        "    VP -> VBZ VP | VBN NP\n",
        "    NNP -> 'Generative' | 'AI'\n",
        "    VBZ -> 'has'\n",
        "    VBN -> 'brought'\n",
        "    JJ -> 'unprecedented'\n",
        "    NN -> 'disruption'\n",
        "\"\"\")\n",
        "\n",
        "# Create a recursive descent parser with the custom grammar\n",
        "custom_parser = nltk.RecursiveDescentParser(custom_grammar)\n",
        "\n",
        "# Function to print the parse tree with downward arrows\n",
        "def custom_pretty_print(tree, indent=\"\"):\n",
        "    if isinstance(tree, nltk.Tree):\n",
        "        print(f\"{indent}{tree.label()} --->\")\n",
        "        for subtree in tree:\n",
        "            custom_pretty_print(subtree, indent + \"    | \")\n",
        "    else:\n",
        "        print(f\"{indent}{tree}\")\n",
        "\n",
        "# Parse the sentence and print the trees\n",
        "tokens = ['Generative', 'AI', 'has', 'brought', 'unprecedented', 'disruption']\n",
        "for tree in custom_parser.parse(tokens):\n",
        "    custom_pretty_print(tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I0liQL_EFtI"
      },
      "source": [
        "# **Observation:**\n",
        "\n",
        "\n",
        "*   The output provides insights into how the input sentence can be syntactically parsed based on the grammar rules. It demonstrates the hierarchical structure of the sentence, breaking it down into phrases and their constituent parts of speech.\n",
        "\n",
        "*   Different parse trees may represent different interpretations of the input sentence, reflecting the ambiguity or multiple possible meanings in natural language. The output helps in understanding how the custom grammar rules influence the parsing process and the resulting syntactic structures.\n",
        "\n",
        "# **Inferences:**\n",
        "\n",
        "\n",
        "*   It helps visualize the hierarchical structure of the sentence and understand its relationships between clauses and phrases.\n",
        "*   The top-down parser started with the start symbol 'S' and recursively applied grammar rules to match the input sentence. It began by expanding 'S' into 'NP VP', then expanded 'NP' into 'NNP NNP', and so on until it matched the input tokens.\n",
        "\n",
        "# **Explanation:**\n",
        "\n",
        "The parse tree generated by the custom recursive descent parser for the given sentence \"Generative AI has brought unprecedented disruption.\" Each line represents a production in the parse tree. Here's a breakdown:\n",
        "\n",
        "* S -->: Indicates the start symbol of the grammar.\n",
        "* NP -->: Represents the noun phrase.\n",
        "* NNP --> Generative: Indicates the proper noun \"Generative.\"\n",
        "* NNP --> AI: Indicates the proper noun \"AI.\"\n",
        "* VP -->: Represents the verb phrase.\n",
        "* VBZ --> has: Indicates the verb \"has.\"\n",
        "* VP -->: Represents another verb phrase.\n",
        "* VBN --> brought: Indicates the past participle verb \"brought.\"\n",
        "* NP -->: Another noun phrase.\n",
        "* JJ --> unprecedented: Indicates the adjective \"unprecedented.\"\n",
        "* NN --> disruption: Indicates the noun \"disruption.\"\n",
        "\n",
        "Overall, the parse tree breaks down the sentence into its grammatical components, showing the structure of the sentence according to the custom grammar.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gslhufM3DU7p"
      },
      "source": [
        "**3) Print the bottom up parser and explain the output (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z3IlHbyVJt7",
        "outputId": "ae880ffd-0cd1-4adc-f438-52c09b5bc1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    |     |     | Generative\n",
            "    |     | NNP <---\n",
            "    |     |     | AI\n",
            "    |     | NNP <---\n",
            "    | NP <---\n",
            "    |     |     | has\n",
            "    |     | VBZ <---\n",
            "    |     |     |     | brought\n",
            "    |     |     | VBN <---\n",
            "    |     |     |     |     | unprecedented\n",
            "    |     |     |     | JJ <---\n",
            "    |     |     |     |     | disruption\n",
            "    |     |     |     | NN <---\n",
            "    |     |     | NP <---\n",
            "    |     | VP <---\n",
            "    | VP <---\n",
            "S <---\n"
          ]
        }
      ],
      "source": [
        "# Create a Shift-Reduce parser with the custom grammar\n",
        "custom_parser = nltk.ShiftReduceParser(custom_grammar)\n",
        "\n",
        "# Function to print the parse tree with upward arrows\n",
        "def custom_pretty_print_bottom_up(tree, indent=\"\"):\n",
        "    if isinstance(tree, nltk.Tree):\n",
        "        for subtree in tree:\n",
        "            custom_pretty_print_bottom_up(subtree, indent + \"    | \")\n",
        "        print(f\"{indent}{tree.label()} <---\")\n",
        "    else:\n",
        "        print(f\"{indent}{tree}\")\n",
        "\n",
        "# Parse the sentence and print the trees\n",
        "tokens = ['Generative', 'AI', 'has', 'brought', 'unprecedented', 'disruption']\n",
        "for tree in custom_parser.parse(tokens):\n",
        "    custom_pretty_print_bottom_up(tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9cbgd4kGNx1"
      },
      "source": [
        "# **Observation:**\n",
        "\n",
        "\n",
        "*   Shift-Reduce parsers construct parse trees in a bottom-up manner, starting from individual tokens and combining them into larger constituents according to grammar rules. The output represents the gradual construction of the parse tree by shifting tokens onto a stack and reducing them through grammar rules until a complete parse tree is formed.\n",
        "\n",
        "*   The output may vary depending on the specific parsing strategy and the grammar rules defined in custom_grammar. Shift-Reduce parsers are generally more efficient but may struggle with certain types of grammatical ambiguity.\n",
        "\n",
        "# **Inferences:**\n",
        "\n",
        "\n",
        "*   It helps understand how individual words can be combined to form meaningful phrases and sentences.\n",
        "*   The bottom-up parser started with the input tokens and attempted to reduce them to the start symbol 'S' by applying grammar rules in reverse. It successively reduced the input tokens using grammar rules until it reached the start symbol 'S'. The successful parsing indicates that the bottom-up parser effectively applied grammar rules to construct the parse tree.\n",
        "\n",
        "# **Explanation:**\n",
        "\n",
        "The parse tree generated by the Shift-Reduce parser for the given sentence \"Generative AI has brought unprecedented disruption.\" Each line represents a production in the parse tree, but the presentation is from bottom to top, showing the reduction steps in a bottom-up manner. Here's a breakdown:\n",
        "\n",
        "* NNP <---: Indicates the proper noun \"Generative\" and \"AI\" being reduced to a noun phrase (NP).\n",
        "* NP <---: Represents the completion of the noun phrase (NP).\n",
        "* VBZ <---: Indicates the verb \"has\" being reduced to a verb phrase (VP).\n",
        "* VBN <---: Indicates the past participle verb \"brought\" being reduced to a verb phrase (VP).\n",
        "* JJ <---: Indicates the adjective \"unprecedented\" being reduced to a noun phrase (NP).\n",
        "* NN <---: Indicates the noun \"disruption\" being reduced to a noun phrase (NP).\n",
        "* NP <---: Represents the completion of the noun phrase (NP).\n",
        "* VP <---: Represents the completion of the verb phrase (VP).\n",
        "* S <---: Represents the completion of the sentence (S).\n",
        "Overall, the parse tree shows the reduction steps performed by the Shift-Reduce parser to build the parse tree from the bottom up.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjJ4UUqvNCzb"
      },
      "source": [
        "**4) Print the Probabilistic Context Free Grammar and explain the output (2 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AlXf9yu9D2j"
      },
      "source": [
        "Approach 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1dT-pWjjrE-",
        "outputId": "615c79b5-9660-49bd-96e5-852f96e440ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S -> NP VP [Prob = 0.0909]\n",
            "NP -> NNP NNP [Prob = 0.0909]\n",
            "NNP -> Generative [Prob = 0.0909]\n",
            "NNP -> AI [Prob = 0.0909]\n",
            "VP -> VBZ VP [Prob = 0.0909]\n",
            "VBZ -> has [Prob = 0.0909]\n",
            "VP -> VBN NP [Prob = 0.0909]\n",
            "VBN -> brought [Prob = 0.0909]\n",
            "NP -> JJ NN [Prob = 0.0909]\n",
            "JJ -> unprecedented [Prob = 0.0909]\n",
            "NN -> disruption [Prob = 0.0909]\n"
          ]
        }
      ],
      "source": [
        "# Parse tree generation\n",
        "custom_grammar_parser = nltk.ChartParser(custom_grammar)\n",
        "parse_trees = list(custom_grammar_parser.parse(tokens))\n",
        "\n",
        "# Function to extract production rules from a parse tree\n",
        "def extract_rules(tree):\n",
        "    if isinstance(tree, nltk.Tree):\n",
        "        return [(tree.label(), ' '.join([child.label() if isinstance(child, nltk.Tree) else child for child in tree]))] + \\\n",
        "               [rule for child in tree if isinstance(child, nltk.Tree) for rule in extract_rules(child)]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Extract production rules from parse trees\n",
        "rules = []\n",
        "for tree in parse_trees:\n",
        "    rules += extract_rules(tree)\n",
        "\n",
        "# Calculate frequencies of production rules\n",
        "rule_counts = defaultdict(int)\n",
        "for rule in rules:\n",
        "    rule_counts[rule] += 1\n",
        "\n",
        "# Calculate probabilities\n",
        "total_rules = sum(rule_counts.values())\n",
        "rule_probabilities = {rule: count / total_rules for rule, count in rule_counts.items()}\n",
        "\n",
        "# Print the Probabilistic Context Free Grammar\n",
        "for rule, probability in rule_probabilities.items():\n",
        "    print(f\"{rule[0]} -> {rule[1]} [Prob = {probability:.4f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuXVWne89YSw"
      },
      "source": [
        "# **Observation:**\n",
        "\n",
        "\n",
        "*  The output provides insights into the probabilistic nature of the custom context-free grammar (custom_grammar). Higher probabilities indicate that certain rules are more likely to be applied during parsing, reflecting the likelihood of specific syntactic structures or constructions in the language.\n",
        "\n",
        "*   The probabilistic grammar captures the variability and uncertainty present in natural language syntax, allowing for more flexible parsing and better handling of ambiguous sentences. By analyzing the probabilities of different production rules, one can understand which syntactic constructions are more prevalent or preferred in the language modeled by the grammar.\n",
        "\n",
        "# **Inferences:**\n",
        "\n",
        "\n",
        "*   The code implements probabilistic parsing using a custom context-free grammar, allowing for the calculation of probabilities for each production rule.\n",
        "This probabilistic approach enables more nuanced parsing, as it considers the likelihood of different syntactic structures rather than treating all rules equally.\n",
        "\n",
        "*   The calculated probabilities offer insights into the underlying patterns and tendencies in the language modeled by the grammar. By analyzing the distribution of rule probabilities, one can infer common syntactic patterns, constructions, and preferences in the language, which aids in language modeling tasks.\n",
        "\n",
        "# **Explanation**\n",
        "\n",
        "This code generates a Probabilistic Context-Free Grammar (PCFG) based on the parse trees generated by a Chart Parser. Here's a breakdown of the code:\n",
        "\n",
        "* Parse Tree Generation: Parse trees are generated using a Chart Parser initialized with the custom grammar.\n",
        "\n",
        "* Function to Extract Production Rules: This function extracts production rules from parse trees. It recursively traverses the parse trees and extracts rules from each tree node.\n",
        "\n",
        "* Extract Production Rules: Production rules are extracted from each parse tree generated by the parser.\n",
        "\n",
        "* Calculate Frequencies of Production Rules: The frequencies of production rules are counted using a defaultdict(int). This counts how many times each rule appears in the parse trees.\n",
        "\n",
        "* Calculate Probabilities: Probabilities are calculated for each production rule by dividing its count by the total number of rules.\n",
        "\n",
        "* Print the Probabilistic Context-Free Grammar: The production rules along with their probabilities are printed.\n",
        "\n",
        "The output provides the production rules of the PCFG along with their probabilities. Each line represents a production rule, with the non-terminal on the left-hand side and its expansion on the right-hand side, along with the probability of that production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q5BWn_N9HDi"
      },
      "source": [
        "Approach 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFRtU2gofYD9",
        "outputId": "7a211734-e90a-432e-a0e8-aed817656642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar with 11 productions (start state = S)\n",
            "    S -> NP VP [1.0]\n",
            "    NP -> NNP NNP [0.5]\n",
            "    NNP -> 'Generative' [0.5]\n",
            "    NNP -> 'AI' [0.5]\n",
            "    VP -> VBZ VP [0.5]\n",
            "    VBZ -> 'has' [1.0]\n",
            "    VP -> VBN NP [0.5]\n",
            "    VBN -> 'brought' [1.0]\n",
            "    NP -> JJ NN [0.5]\n",
            "    JJ -> 'unprecedented' [1.0]\n",
            "    NN -> 'disruption' [1.0]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the sentence\n",
        "tokens = sentence.split()\n",
        "\n",
        "# Create a recursive descent parser with the custom grammar\n",
        "parser = nltk.RecursiveDescentParser(custom_grammar)\n",
        "\n",
        "# Parse the sentence and get the parse tree\n",
        "for tree in parser.parse(tokens):\n",
        "    # Extract productions from the parse tree\n",
        "    productions = tree.productions()\n",
        "\n",
        "# Define the start symbol as a Nonterminal object\n",
        "start_symbol = nltk.Nonterminal('S')\n",
        "\n",
        "# Induce a PCFG from the custom grammar and the extracted productions\n",
        "pcfg_grammar = nltk.induce_pcfg(start_symbol, productions)\n",
        "\n",
        "# Print the PCFG\n",
        "print(pcfg_grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vfpQ2I2lLAP"
      },
      "source": [
        "# **Observation:**\n",
        "\n",
        "\n",
        "*  A Probabilistic Context-Free Grammar is induced from the custom grammar and the extracted productions. The PCFG extends the context-free grammar by assigning probabilities to productions, capturing the likelihood of generating a certain constituent from another.\n",
        "\n",
        "*   The induced Probabilistic Context-Free Grammar can be used to evaluate the performance of the grammar in capturing the syntactic structures of the language. By analyzing the distribution of rule probabilities, one can assess the adequacy and accuracy of the grammar in modeling the language.\n",
        "\n",
        "# **Inferences:**\n",
        "\n",
        "\n",
        "*   The Probabilistic Context-Free Grammar provides insights into the probabilistic nature of the grammar. Each production rule is associated with a probability, indicating the likelihood of generating a constituent based on that rule. High probabilities suggest frequent or preferred syntactic constructions, while low probabilities may indicate less common or less preferred constructions in the language.\n",
        "\n",
        "*   The induced Probabilistic Context-Free Grammar serves as a language model, capturing the syntactic patterns and tendencies present in the custom grammar and the parsed sentences. By analyzing the distribution of rule probabilities, one can gain insights into the underlying structure and variability of the language modeled by the grammar.\n",
        "\n",
        "# **Explanation:**\n",
        "\n",
        "This code tokenizes a sentence, then creates a Recursive Descent Parser using a custom grammar. It parses the sentence and extracts the productions from the resulting parse tree. The start symbol is defined as a Nonterminal object, and then a PCFG is induced from the custom grammar and the extracted productions.\n",
        "\n",
        "The output shows the PCFG with its productions and corresponding probabilities. Each line represents a production rule, where the non-terminal on the left-hand side transitions to the terminals or non-terminals on the right-hand side, along with the probability of that transition.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVG-L2sC9_RJ"
      },
      "source": [
        "**DIFFERENCE between approach 1 and apporach 2**\n",
        "\n",
        "If we want to create a PCFG grammar directly from a set of predefined productions with equal probabilities, the approach 1 is preferred. On the other hand, if you want to calculate probabilities based on observed frequencies from parse trees, the approach 2 is preferred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljkuftKunR3L"
      },
      "source": [
        "**5) Print the Viterbi parser and explain the output (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_bxmRkbD08G",
        "outputId": "c8c7abbd-0ff4-427a-8cbc-2217515d2b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('S', (('NP', (('NNP', 'Generative'), ('NNP', 'AI'))), ('VP', (('VBZ', 'has'), ('VP', (('VBN', 'brought'), ('NP', (('JJ', 'unprecedented'), ('NN', 'disruption')))))))))\n",
            "\n",
            "\n",
            "===========================\n",
            "**IN FLOW Structure**\n",
            "\n",
            "\n",
            "(S\n",
            "  (NP (NNP (Generative )) (NNP (AI )))\n",
            "  (VP\n",
            "    (VBZ (has ))\n",
            "    (VP\n",
            "      (VBN (brought ))\n",
            "      (NP (JJ (unprecedented )) (NN (disruption ))))))\n"
          ]
        }
      ],
      "source": [
        "# Define the grammar rules\n",
        "grammar = {\n",
        "    'S': [['NP', 'VP']],\n",
        "    'NP': [['JJ', 'NN'], ['NNP', 'NNP']],\n",
        "    'VP': [['VBZ', 'VP'], ['VBN', 'NP']],\n",
        "    'NNP': [['Generative'], ['AI']],\n",
        "    'VBZ': [['has']],\n",
        "    'VBN': [['brought']],\n",
        "    'JJ': [['unprecedented']],\n",
        "    'NN': [['disruption']]\n",
        "}\n",
        "\n",
        "# Implement Viterbi parsing algorithm\n",
        "def viterbi_parser(sentence, grammar):\n",
        "    words = sentence.split()\n",
        "    chart = [[{} for _ in range(len(words) + 1)] for _ in range(len(words))]\n",
        "\n",
        "    # Initialization\n",
        "    for i in range(len(words)):\n",
        "        for key in grammar.keys():\n",
        "            if ([words[i]] in grammar[key]):\n",
        "                chart[i][i+1][key] = (1, words[i])\n",
        "\n",
        "    # Parsing\n",
        "    for span in range(2, len(words) + 1):\n",
        "        for begin in range(len(words) - span + 1):\n",
        "            end = begin + span\n",
        "            for split in range(begin + 1, end):\n",
        "                for A in grammar.keys():\n",
        "                    for rule in grammar[A]:\n",
        "                        if len(rule) == 2:\n",
        "                            B, C = rule\n",
        "                            if B in chart[begin][split] and C in chart[split][end]:\n",
        "                                prob = chart[begin][split][B][0] * chart[split][end][C][0]\n",
        "                                if A not in chart[begin][end] or prob > chart[begin][end][A][0]:\n",
        "                                    chart[begin][end][A] = (prob, B, C, split)\n",
        "\n",
        "    def reconstruct(begin, end, symbol):\n",
        "        if end == begin + 1:\n",
        "            return (symbol, chart[begin][end][symbol][1])\n",
        "        else:\n",
        "            prob, B, C, split = chart[begin][end][symbol]\n",
        "            if symbol == 'VP':\n",
        "                return (symbol, (reconstruct(begin, split, B), reconstruct(split, end, C)))\n",
        "            else:\n",
        "                return (symbol, (reconstruct(begin, split, B), reconstruct(split, end, C)))\n",
        "\n",
        "    return reconstruct(0, len(words), 'S')\n",
        "\n",
        "# Function to construct a tree\n",
        "def construct_tree(parse_tree):\n",
        "    symbol, children = parse_tree\n",
        "    if isinstance(children, tuple):\n",
        "        return nltk.Tree(symbol, [construct_tree(child) for child in children])\n",
        "    else:\n",
        "        return nltk.Tree(symbol, [nltk.Tree(children, [])])\n",
        "\n",
        "# Test the parser\n",
        "sentence = \"Generative AI has brought unprecedented disruption\"\n",
        "parse_tree = viterbi_parser(sentence, grammar)\n",
        "print(parse_tree)\n",
        "\n",
        "\n",
        "# Print the tree\n",
        "tree = construct_tree(parse_tree)\n",
        "print(\"\\n\")\n",
        "print(\"===========================\")\n",
        "print(\"**IN FLOW Structure**\")\n",
        "print(\"\\n\")\n",
        "print(tree)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kPXp0of61zz"
      },
      "source": [
        "# **Observation:**\n",
        "\n",
        "\n",
        "*   The Viterbi parsing algorithm efficiently finds the most likely parse tree for a given sentence based on the provided Probabilistic Context-Free Grammar and grammar rules. The output provides insights into the most probable syntactic structure of the input sentence according to the grammar rules and the likelihood of different parse tree configurations.\n",
        "\n",
        "*   By considering probabilities during parsing, the Viterbi algorithm handles uncertainty and ambiguity in natural language syntax, providing a robust framework for syntactic parsing.\n",
        "\n",
        "# **Inferences:**\n",
        "\n",
        "\n",
        "*   The code implements the Viterbi parsing algorithm, which is a dynamic programming algorithm used to find the most likely parse tree for a given sentence in the context of probabilistic context-free grammars. The algorithm iteratively fills up a chart with probabilities of non-terminal symbols spanning different spans of the input sentence. It computes probabilities for non-terminal symbols by considering all possible combinations of subspans and their corresponding probabilities.\n",
        "\n",
        "*   The code prints the reconstructed parse tree, which represents the most likely syntactic structure for the input sentence according to the given grammar and the Viterbi parsing algorithm. The parse tree is printed in a hierarchical structure, showing the relationships between different constituents of the sentence.\n",
        "\n",
        "# **Explanation:**\n",
        "\n",
        "The output represents a parse tree structure using the viterbi algorithm for the input sentence \"Generative AI has brought unprecedented disruption\" based on the provided grammar rules. It's structured as follows:\n",
        "\n",
        "* The root of the tree is labeled as 'S', indicating the sentence.\n",
        "* The 'S' node has two children: 'NP' and 'VP', representing the noun phrase and verb phrase, respectively.\n",
        "* The 'NP' node further branches into two 'NNP' nodes, representing proper nouns \"Generative\" and \"AI\".\n",
        "* The 'VP' node contains two children: 'VBZ' and 'VP'. 'VBZ' represents the verb \"has\", while the second 'VP' represents a nested verb phrase.\n",
        "* The nested 'VP' node consists of 'VBN' and 'NP'. 'VBN' represents the past participle \"brought\", and 'NP' represents a nested noun phrase.\n",
        "* The nested 'NP' node contains 'JJ' and 'NN', representing the adjective \"unprecedented\" and the noun \"disruption\", respectively.\n",
        "\n",
        "Overall, the tree structure reflects the hierarchical syntactic relationships within the input sentence based on the given grammar rules.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}